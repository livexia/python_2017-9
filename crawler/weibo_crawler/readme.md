## 项目结构图
    weibo_crawler
    ├── breakpoint.json #断点保存
    ├── captcha.png #获取到的滑动验证码
    ├── cookies.json    #保存的cookie
    ├── crack_weibo_slide.py    #破解微博手机端的滑动验证码图形处理的部分
    ├── general.py  #文件读取写入，存入mongodb的部分
    ├── login_weibo.py  #微博的登陆，含有手机端和PC端，入口为：normal_login()、mobile_login
    ├── main.py #入口
    ├── readme.md
    ├── result  #抓取数据的本地存储etc.
    ├── templates   #预先获得的所有手机端滑动验证码的可能性
    └── weibo_spider.py #抓取微博数据


具体：

	1. 本周前几天，我在尝试利用对PC端验证码的图像变换，然后利用OCR技术识别验证码。微博的pc验证码含有旋转和一条曲线，这使得利用图形的方法几乎不可行，垂直投影不能切割。于是我找了很多资料，发现都是类似的，先切分再OCR。

	2. 直接利用图形学的手段不能简单的直接识别验证码，于是我又去看了利用神经卷积网络的方法来做一个识别。这个方法是先有大量的训练数据，然后建立模型，不停训练模型，然后给出结果。我的确获取到了大量的新浪微博验证码，但是靠我对他们进行标记相当的耗时。

	3. 上面两个手段我都没有真正的做完，原因是我对这两个手段中用到的技术几乎没有接触过。于是我上网找了有人对新浪微博验证的破解手段。我发现了一个相当新奇的方法，破解手机端新浪微博的滑动验证登陆。

	4. 滑动验证：以固定的顺序在四个点间用鼠标滑动，一个点仅能经过一次。这样的滑动验证最多有24种可能，那么只要在登录的时候把验证码截图保存，然后和24种可能进行比对，得到正确的顺序，再利用selenium进行模拟滑动。然后登录成功后把得到的cookie保存下来，传递给requests使用。这样仅仅在登录时会花费较多时间。虽然滑动验证的部分参考了他人的代码，但是我在其中也加入了自己的调节。我在获取到验证码和匹配本地验证码的部分加入了，多进程与多线程，这样匹配的速度更快。利用phantomjs而不是chrome等，这样可以实现后台的操作。其中对于当下验证码的截取，也包含我自己的内容，对于图片先做一次初剪裁，再利用PIL进行准确剪裁。

	5. 本周算是基本上做完了新浪微博爬虫的最复杂的部分，具体数据的爬取这些都可以以后再加上小功能。新浪微博的爬虫到本周就算一个收尾了，代码见github，这里就不贴了。下周将是学习其他的内容。

滑动验证破解参考：
>1. https://github.com/Python3WebSpider/CrackWeiboSlide
>2. https://github.com/LiuXingMing/WeiboSliderCode
